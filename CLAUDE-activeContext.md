# Active Context - 意心AI心理咨询平台

**最后更新:** 2025年1月

---

## 当前会话状态

### 会话目标
实现沉浸式纯语音交互咨询界面，去除传统对话框设计，让AI主动引导用户进行心理咨询对话

### 已完成任务 ✅

1. **完全重构语音咨询界面 (Consultation.tsx)**
   - 去除所有对话框和聊天气泡
   - 实现大圆形语音按钮（192px）作为唯一交互元素
   - 移除文字输入框，改为纯语音交互
   - AI回复以文字+语音双重形式呈现

2. **AI主动引导机制**
   - AI在会话初始化时自动问候
   - 根据KB01-05不同阶段提供个性化问候语
   - 问候逻辑在客户端实现，避免不必要的API调用

3. **后端语音API修复**
   - 修复 `/api/messages/voice` 端点的用户消息保存逻辑
   - 添加fallback机制：百炼语音API失败时自动回退到文本API
   - 改进错误处理和用户提示

4. **视觉交互改进**
   - 实时状态反馈（录音/说话/处理中）
   - 动画效果（ping/pulse/scale）
   - 渐变背景装饰
   - 响应式设计

5. **路由和导航**
   - 更新App.tsx添加 `/consultation/:sessionId` 路由
   - Dashboard添加"语音咨询"按钮
   - 自动区分文字会话和语音会话

6. **TypeScript类型修复 (2025-01-13)**
   - 修复messages.ts中的复杂类型推断错误
   - 使用明确的UsageStats和EthicsCheckResult类型
   - 构建成功通过

### 待完成任务 🚧

#### 高优先级
1. **会话历史RAG（上下文持久化）**
   - 为每个用户创建向量数据库索引
   - 实现跨会话的记忆检索
   - 在生成回复时整合历史上下文
   - 状态: 未开始

2. **实时语音对话（WebRTC）**
   - 前端集成WebRTC实时音频流
   - 后端WebSocket连接处理
   - 实时ASR和TTS集成
   - 全双工通信替代当前半双工模式
   - 状态: 未开始

#### 中优先级
3. **语音识别优化**
   - 当前使用占位符 `[语音消息 - 暂时无法转写]`
   - 需要集成真实的ASR服务（如百炼API或第三方）
   - 状态: 需要实现

4. **语音合成优化**
   - 当前回退到浏览器TTS
   - 需要确保百炼TTS正常工作
   - 考虑音色、语速、停顿等参数调优
   - 状态: 需要优化

5. **移动端适配**
   - 优化触摸交互体验
   - 调整语音按钮大小和位置
   - 测试各种移动浏览器兼容性
   - 状态: 未测试

#### 低优先级
6. **会话回放功能**
   - 允许用户回放历史语音对话
   - 需要存储音频文件
   - 状态: 未规划

7. **语音情绪分析**
   - 分析用户语音中的情绪状态
   - 调整AI回复策略
   - 状态: 未规划

---

## 最近的重要决策

### 1. 为什么完全去除对话框？
**决策:** 采用纯语音交互界面，只保留大圆形按钮
**原因:**
- 模拟真实心理咨询场景（面对面，不看屏幕）
- 减少视觉干扰，让用户专注于语音交流
- 差异化体验，区别于传统聊天机器人

### 2. 为什么AI主动问候而非等待用户？
**决策:** AI在会话开始时主动问候并引导
**原因:**
- 符合真实心理咨询师的行为模式
- 降低用户的心理障碍（不知道说什么）
- 体现AI的主动性和专业性

### 3. 为什么问候逻辑在前端实现？
**决策:** 初始问候在客户端生成并播放，不调用后端API
**原因:**
- 避免不必要的API调用和数据库写入
- 加快响应速度（无需等待网络）
- 问候语是固定的，不需要AI生成

### 4. 为什么添加语音API fallback？
**决策:** 语音API失败时自动回退到文本API
**原因:**
- 百炼语音API可能未完全配置或不稳定
- 确保基本功能可用（即使无语音识别）
- 渐进式增强策略

---

## 已知问题

### 1. 语音转文字占位符
**问题:** 当百炼语音API不可用时，用户消息显示为 `[语音消息 - 暂时无法转写]`
**影响:** 用户看不到自己说了什么
**临时方案:** 使用fallback到文本API
**长期方案:** 集成可靠的ASR服务

### 2. 语音API响应格式不明确
**问题:** 不清楚百炼语音API的实际响应格式
**影响:** 可能无法正确提取用户语音转文字和AI音频
**状态:** 需要查阅API文档或测试

### 3. 移动端浏览器兼容性未测试
**问题:** 语音录制和播放在移动端可能有问题
**影响:** iOS Safari、微信内置浏览器等可能不支持
**状态:** 需要测试

---

## 技术债务

1. **VoiceConsultation.tsx 文件冗余**
   - 现在有Consultation.tsx和VoiceConsultation.tsx两个文件
   - 内容基本相同
   - 应该删除VoiceConsultation.tsx或合并

2. ~~**语音API类型定义不完整**~~ ✅ 已修复 (2025-01-13)
   - ~~messages.ts中使用复杂的类型推断~~
   - 现已使用明确的UsageStats和EthicsCheckResult类型

3. **错误处理不够细致**
   - 网络错误、权限错误、API错误应该区分处理
   - 给用户更友好的提示

4. **缺少单元测试**
   - 语音相关逻辑应该有测试覆盖
   - KB引擎、RAG加载器等核心服务需要测试

---

## 环境配置

### 开发环境
- Node.js 18+
- npm 9+
- Git

### 必需环境变量
```bash
# Supabase
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_ANON_KEY=eyJxxx...
SUPABASE_SERVICE_KEY=eyJxxx...

# JWT
JWT_SECRET=your-secret-key

# 百炼API (可选)
BAILIAN_ENDPOINT=https://dashscope.aliyuncs.com
BAILIAN_API_KEY=sk-xxx...
```

### 本地开发命令
```bash
# 安装依赖
npm install

# 启动开发服务器
npm run dev

# 构建
npm run build

# 类型检查
npm run type-check
```

---

## 下一步行动

### 即将进行
1. **测试当前语音咨询功能**
   - 在实际环境中测试语音录制
   - 验证AI问候是否正常播放
   - 检查错误处理是否友好

2. **决定优先级**
   - 会话历史RAG vs 实时语音对话
   - 根据用户反馈调整优先级

### 待讨论
- 语音识别服务选择（百炼 vs 第三方）
- 向量数据库方案（Supabase pgvector vs 专用服务）
- WebRTC实现复杂度评估

---

## 参考资源

- [项目GitHub仓库](https://github.com/ChineseManHuang/YIXIN)
- [Vercel部署](https://yixin-opal.vercel.app)
- [语音咨询功能文档](./VOICE_CONSULTATION_GUIDE.md)
- [百炼API文档](https://help.aliyun.com/zh/dashscope/)
- [Supabase文档](https://supabase.com/docs)
